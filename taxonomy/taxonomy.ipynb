{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELAsTiCC taxonomy\n",
    "\n",
    "_Alex Malz (GCCL@RUB)_ , _Rob Knop (raknop@lbl.gov)_\n",
    "\n",
    "The original thought behind this was to define a \"bit\" mask (really, the decimal equivalent), but in pratice that's not what we have.  Rather, what we have is a hierarchical classification, where each level of the hierarchy is one power of 10, and categories the next level down are different for each parent category.  The lowest power of 10 that is not zero represents how specific the category is; if the ones digit is not zero, then the category is as specific as the taxonomy gets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of the taxonomy\n",
    "\n",
    "Brokers will ingest alerts produced by the ELAsTiCC team (eventually, produced by LSST).  Each alert will have information about one _DiaSource_ (DIA=\"Differential Imaging Analysis\"); this is a single observation at one time of a _DiaObject_.  A _DiaObject_ represents a single astronomical object or event; in practice, it's defined by a position on the sky.  A new source found at the position of an existing object will be assigned to that existing object.  The alert for a _DiaSource_ will also include the data for that source's _DiaObject_, as well as previously-detected sources for that same object, and (if the object was discovered at least a day ago) forced photometry (stored using the _DiaForcedSource_ schema) dating back to at most 30 days before the first detection fo the object.\n",
    "\n",
    "Brokers will then apply whatever algorithms they have to estimate classifications for the source.  Each different algorithm a broker uses is called a _classifier_.  When a classifier responds to an alert, it should produce a set of (_classId_, _probability_) pairs.  All of the _probability_ values for a single source should sum to 1.  The _classId_ values are described by this taxonomy; the actual hierarchical list of values can be found near the bottom of this notebook.\n",
    "\n",
    "### Avro schema\n",
    "\n",
    "All schema for ELAsTiCC can be found in https://github.com/LSSTDESC/elasticc/tree/main/alert_schema\n",
    "\n",
    "Brokers will ingest the \"alert\" schema; as of this writing, the current version is 0.9.1 : https://github.com/LSSTDESC/elasticc/blob/main/alert_schema/elasticc.v0_9_1.alert.avsc  That schema includes the object, source, and forcedsource schema (all in the same directory).\n",
    "\n",
    "Brokers will publish the \"brokerClasification\" schema; again, as of this writing, the current verison is 0.9.1 : https://github.com/LSSTDESC/elasticc/blob/main/alert_schema/elasticc.v0_9_1.brokerClassification.avsc\n",
    "\n",
    "\n",
    "### Documentation of specific categories\n",
    "\n",
    "* **Meta/Residual** -- All of the probabilities returned for a single alert should sum to 1.  This is the categorory to put the probaiblity for \"not any of the other things I've assigned a probability for\".  One use of this would be for yes/no binary categorizer.  Suppose you just want to report the probability that an event is a SNIa.  You'd assign that probability to the SNIa categority, and one minus that probability to this category.  So, if the algorithm produced a 33% chance it's a SNIa, the SNIa category would get 0.33, and the Meta/Residual category would get 0.67.\n",
    "\n",
    "* **Meta/NotClassified** -- Use this category to report that your algoirthm chose not to classify a source; assign a probability of 1 to this category in that case.  The purpose of this is so that we can diagnose whether and why alerts are getting dropped.  If we receive a this classification, we know the alert made it all the way through the system from, but that the algorithm did not think it had enough information to actually supply a classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the integer codes\n",
    "\n",
    "The idea is that every level of the tree corresponds to one digit in the number for the classification.\n",
    "\n",
    "* 1000s : General category (Meta info, static object, non-recurring object, recurring object)\n",
    "* 100s : Variable vs. Static object. (Static object would be something like a persistent subtraction artifact that doesn't get caught by the LSST R/B system.)\n",
    "* 10s : Specific category (e.g. is it a SN-like variable, a periodic recurring object, non-perodic recurring object, etc.)\n",
    "* 1s : Specific cateogorization (SNIa, SNIb, AGN, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelib import Node, Tree\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a phylogenetic tree\n",
    "\n",
    "Given the hierarchical class relationships, make a tree diagram (and record some hopefully useful information)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping\n",
    "\n",
    "We need to think about how to sort through the classification information.\n",
    "`directory` and `index` are very simplistic starting points.\n",
    "It'll be easier when we have a better idea of what subsampling operations we'll perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = {}\n",
    "index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxdep = 3\n",
    "def branch(tree, parent, children, prepend=[\"Other\"], append=None, directory=directory, index=index):\n",
    "    if prepend is not None:\n",
    "        proc_pre = [parent + \"/\" + pre for pre in prepend]\n",
    "        children = proc_pre + children\n",
    "    if append is not None:\n",
    "        proc_app = [parent + \"/\" + appe for app in append]\n",
    "        children = children + proc_app\n",
    "    tmp = parent\n",
    "    level = 0\n",
    "    while tree.ancestor(tmp) is not None:\n",
    "        level += 1\n",
    "        tmp = tree.ancestor(tmp)\n",
    "    directory[parent] = {}\n",
    "    for i, child in enumerate( children ):\n",
    "        directory[parent][child] = i\n",
    "#         print(index[parent], type(index[parent]))\n",
    "        if index[parent] != '':\n",
    "            index[child] = str(int(index[parent]) + (i+1)* 10 ** (maxdep-level))\n",
    "        else:\n",
    "            index[child] = str((i+1)* 10 ** (maxdep-level))\n",
    "        tree.create_node(index[child]+\" \"+child, child, parent=parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be better to start with something like `directory` than to build it as we go along, but, hey, this is a hack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Alert\n",
      "├── 0 Meta\n",
      "│   ├── 100 Meta/Other\n",
      "│   ├── 200 Residual\n",
      "│   └── 300 NotClassified\n",
      "├── 1000 Static\n",
      "│   └── 1100 Static/Other\n",
      "└── 2000 Variable\n",
      "    ├── 2100 Variable/Other\n",
      "    ├── 2200 Non-Recurring\n",
      "    │   ├── 2210 Non-Recurring/Other\n",
      "    │   ├── 2220 SN-like\n",
      "    │   │   ├── 2221 SN-like/Other\n",
      "    │   │   ├── 2222 Ia\n",
      "    │   │   ├── 2223 Ib/c\n",
      "    │   │   ├── 2224 II\n",
      "    │   │   ├── 2225 Iax\n",
      "    │   │   └── 2226 91bg\n",
      "    │   ├── 2230 Fast\n",
      "    │   │   ├── 2231 Fast/Other\n",
      "    │   │   ├── 2232 KN\n",
      "    │   │   ├── 2233 M-dwarf Flare\n",
      "    │   │   ├── 2234 Dwarf Novae\n",
      "    │   │   └── 2235 uLens\n",
      "    │   └── 2240 Long\n",
      "    │       ├── 2241 Long/Other\n",
      "    │       ├── 2242 SLSN\n",
      "    │       ├── 2243 TDE\n",
      "    │       ├── 2244 ILOT\n",
      "    │       ├── 2245 CART\n",
      "    │       └── 2246 PISN\n",
      "    └── 2300 Recurring\n",
      "        ├── 2310 Recurring/Other\n",
      "        ├── 2320 Periodic\n",
      "        │   ├── 2321 Periodic/Other\n",
      "        │   ├── 2322 Cepheid\n",
      "        │   ├── 2323 RR Lyrae\n",
      "        │   ├── 2324 Delta Scuti\n",
      "        │   ├── 2325 EB\n",
      "        │   └── 2326 LPV/Mira\n",
      "        └── 2330 Non-Periodic\n",
      "            ├── 2331 Non-Periodic/Other\n",
      "            └── 2332 AGN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = Tree()\n",
    "\n",
    "basename = \"Alert\"\n",
    "\n",
    "index[basename] = ''\n",
    "tree.create_node(index[basename] + \" \" + basename, basename)\n",
    "\n",
    "# need spot for residual, choose not to classify -- metacategory? possibly rename to \"Flagged\"?\n",
    "index[\"Meta\"] = \"0\"\n",
    "tree.create_node(index[\"Meta\"] + \" Meta\", \"Meta\", parent = basename)\n",
    "branch(tree, \"Meta\", [\"Residual\", \"NotClassified\"])\n",
    "\n",
    "branch(tree, basename, [\"Static\", \"Variable\"], prepend=[] )\n",
    "\n",
    "branch(tree, \"Static\", [] )\n",
    "\n",
    "branch(tree, \"Variable\", [\"Non-Recurring\", \"Recurring\"] )\n",
    "\n",
    "branch(tree, \"Recurring\", [\"Periodic\", \"Non-Periodic\"])\n",
    "\n",
    "branch(tree, \"Periodic\", [\"Cepheid\", \"RR Lyrae\", \"Delta Scuti\", \"EB\", \"LPV/Mira\"])\n",
    "\n",
    "branch(tree, \"Non-Periodic\", [\"AGN\"])\n",
    "\n",
    "branch(tree, \"Non-Recurring\", [\"SN-like\", \"Fast\", \"Long\"])\n",
    "\n",
    "branch(tree, \"SN-like\", [\"Ia\", \"Ib/c\", \"II\", \"Iax\", \"91bg\"])\n",
    "\n",
    "branch(tree, \"Fast\", [\"KN\", \"M-dwarf Flare\", \"Dwarf Novae\", \"uLens\"])\n",
    "\n",
    "branch(tree, \"Long\", [\"SLSN\", \"TDE\", \"ILOT\", \"CART\", \"PISN\"])\n",
    "\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building a structure for hierarchical classification\n",
    "\n",
    "The whole point of this, for me, is for the classification to have corresponding posterior probabilities, or at least confidence flags or scores, because I'd want to use them to rapidly select follow-up candidates.\n",
    "[This](https://community.lsst.org/t/projects-involving-irregularly-shaped-data/4466) looks potentially relevant.\n",
    "I guess it could also be used for packaging up additional features into an alert without bloating it up too much."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rob_mess_conda",
   "language": "python",
   "name": "rob_mess_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
